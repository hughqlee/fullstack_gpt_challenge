import os
import streamlit as st

from langchain.document_loaders import SitemapLoader
from langchain.schema.runnable import RunnableLambda, RunnablePassthrough
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores.faiss import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
def parse_page(soup):
    header = soup.find("header")
    footer = soup.find("footer")
    if header:
        header.decompose()
    if footer:
        footer.decompose()
    return (
        str(soup.get_text())
        .replace("\n", " ")
        .replace("\xa0", " ")
    )

@st.cache_data(show_spinner="Loading website...")
def load_website(api_key):
    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
        chunk_size=500,
        chunk_overlap=100,
    )
    loader = SitemapLoader(
        web_path="https://developers.cloudflare.com/sitemap-0.xml",
        filter_urls=[
            "https://developers.cloudflare.com/ai-gateway",
            "https://developers.cloudflare.com/vectorize",
            "https://developers.cloudflare.com/workers-ai",
        ]
    )
    docs = loader.load_and_split(splitter)
    return FAISS.from_documents(
        docs,
        OpenAIEmbeddings(openai_api_key=api_key),
    ).as_retriever()

def format_docs(docs):
    return "\n\n".join(document.page_content for document in docs)

st.set_page_config(
    page_title="SiteGPT",
    page_icon="ğŸ¤–",
)

st.title("SiteGPT")

with st.sidebar:
    st.markdown("[ğŸ”— Github Repo](https://github.com/hughqlee/fullstack_gpt_challenge)")
    openai_api_key = st.text_input("OpenAI API Key", value=os.environ.get("OPENAI_API_KEY"), type="password")
    
# API Keyê°€ ì…ë ¥ë˜ì§€ ì•Šìœ¼ë©´ ì§„í–‰ ë¶ˆê°€ ì•ˆë‚´
if not openai_api_key:
    st.warning("OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    st.stop()

# LLM ì´ˆê¸°í™” (API í‚¤ê°€ ìˆì„ ë•Œë§Œ)
llm = ChatOpenAI(
    temperature=0.1,
    openai_api_key=openai_api_key
)

# ì›¹ì‚¬ì´íŠ¸ ë¡œë“œ
retriever = load_website(openai_api_key)

# RAG í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
prompt = ChatPromptTemplate.from_messages([
    ("system", """
    You are a helpful assistant that answers questions based on the provided context from Cloudflare documentation.
    
    Context: {context}
    
    Please answer the question based on the provided context. If the information is not available in the context, please say so.
    """),
    ("human", "{question}")
])

# RAG ì²´ì¸ êµ¬ì„±
chain = (
    {
        "context": retriever | RunnableLambda(format_docs),
        "question": RunnablePassthrough(),
    }
    | prompt
    | llm
)

st.markdown("### Cloudflare AI ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”!")

# ìƒ˜í”Œ ì§ˆë¬¸ë“¤ì„ ë²„íŠ¼ìœ¼ë¡œ ì œê³µ
st.markdown("**ìƒ˜í”Œ ì§ˆë¬¸ë“¤:**")
col1, col2, col3 = st.columns(3)

with col1:
    if st.button("ğŸ’° LLaMA-2 ëª¨ë¸ ê°€ê²©"):
        sample_question = "What is the price per 1M input tokens of the llama-2-7b-chat-fp16 model?"
        st.session_state.question = sample_question

with col2:
    if st.button("ğŸšª AI Gateway ê¸°ëŠ¥"):
        sample_question = "What can I do with Cloudflare's AI Gateway?"
        st.session_state.question = sample_question

with col3:
    if st.button("ğŸ“Š Vectorize ì¸ë±ìŠ¤ ìˆ˜"):
        sample_question = "How many indexes can a single account have in Vectorize?"
        st.session_state.question = sample_question

# ì§ˆë¬¸ ì…ë ¥
question = st.text_input(
    "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:",
    value=st.session_state.get("question", ""),
    placeholder="ì˜ˆ: What is the price per 1M input tokens of the llama-2-7b-chat-fp16 model?"
)

if question:
    with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        try:
            # RAG ì²´ì¸ ì‹¤í–‰
            response = chain.invoke(question)
            
            st.markdown("### ë‹µë³€:")
            st.markdown(response.content)
            
            # ê´€ë ¨ ë¬¸ì„œ í‘œì‹œ (ì„ íƒì‚¬í•­)
            with st.expander("ì°¸ê³ í•œ ë¬¸ì„œë“¤ ë³´ê¸°"):
                docs = retriever.get_relevant_documents(question)
                for i, doc in enumerate(docs[:3]):  # ìƒìœ„ 3ê°œ ë¬¸ì„œë§Œ í‘œì‹œ
                    st.markdown(f"**ë¬¸ì„œ {i+1}:**")
                    st.markdown(f"ì¶œì²˜: {doc.metadata.get('source', 'Unknown')}")
                    st.markdown(f"ë‚´ìš©: {doc.page_content[:500]}...")
                    st.markdown("---")
                    
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "question" not in st.session_state:
    st.session_state.question = ""
        


