{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c05a776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6464e90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 문서 로드 및 스플릿\n",
    "loader = UnstructuredFileLoader(\"document.txt\")\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\\n\", chunk_size=600, chunk_overlap=100\n",
    ")\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "# 2) 임베딩 + 캐시\n",
    "embeddings = OpenAIEmbeddings()\n",
    "cache_store = LocalFileStore(\"cache\")\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_store)\n",
    "\n",
    "# 3) 벡터스토어 & 검색기\n",
    "vectorstore = FAISS.from_documents(docs, embedding=cached_embeddings)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 4) 대화 메모리\n",
    "memory = ConversationBufferMemory(memory_key=\"history\", return_messages=True)\n",
    "\n",
    "# 5) 각 청크에서 관련 텍스트 뽑아 결합하는 함수\n",
    "map_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     \"You are a helpful assistant. Answer questions using only the following context. If you don't know the answer just say you don't know, don't make it up: {context}\"),\n",
    "    (\"user\", \"Question:\\n{question}\"),\n",
    "])\n",
    "map_llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "# 6) 단일 RunnableLambda로 Map + Reduce 입력 준비\n",
    "def map_and_prepare(inputs: dict) -> dict:\n",
    "    question = inputs[\"input\"]\n",
    "    # 1) 검색\n",
    "    docs = retriever.get_relevant_documents(question)\n",
    "    # 2) 각 청크 평가\n",
    "    snippets = []\n",
    "    for doc in docs:\n",
    "        out = map_prompt | map_llm\n",
    "        resp = out.invoke({\"context\": doc.page_content, \"question\": question})\n",
    "        text = resp.content.strip()\n",
    "        if text:\n",
    "            snippets.append(text)\n",
    "    # 3) 추출된 텍스트 결합\n",
    "    combined_context = \"\\n\\n\".join(snippets)\n",
    "    return {\"context\": combined_context, \"input\": question, \"history\": inputs[\"history\"]}\n",
    "\n",
    "map_reduce_step = RunnablePassthrough.assign(history=lambda _: memory.load_memory_variables({})['history'])\n",
    "map_reduce_step |= RunnableLambda(map_and_prepare)\n",
    "\n",
    "# 7) 최종 프롬프트와 LLM\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"Given the following extracted text snippets and conversation history, answer the question. \"\n",
    "     \"If you don't know, just say you don't know. Do not invent an answer.\"),\n",
    "    (\"assistant\", \"Extracted Context:\\n{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "final_llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "# 8) 전체 파이프라인 조립\n",
    "chain = map_reduce_step | final_prompt | final_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1a530d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Yes, according to the text, Jones, Aaronson, and Rutherford were guilty of the crimes they were charged with.')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"Is Aaronson guilty?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6f6d686e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='He wrote \"FREEDOM IS SLAVERY\" and \"TWO AND TWO MAKE FIVE\" on the table.')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"What message did he write in the table?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "89560a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Julia is a character who was involved in a relationship with Winston, the protagonist of the story.')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"Who is Julia?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6c4916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
